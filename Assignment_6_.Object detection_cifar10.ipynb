{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil Karamkar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (5.2.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre processing img data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40079 images belonging to 10 classes.\n",
      "Found 9921 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"cifar-10-img/train\"\n",
    "test_dir = \"cifar-10-img/test\"\n",
    "#instances | used to preprocess  data for training and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,   # normalizes the pixel values of images \n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    ")\n",
    "\n",
    "# here batch_size is the number of images in each batch\n",
    "\n",
    "train_batch_size = 5000\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_batch_size = 1000\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=test_batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting only first batch with 5000 images as train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train =  train_generator[0]\n",
    "x_test, y_test = test_generator[0]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load in a pre-trained CNN model trained on a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 without top layers\n",
    "weights_path = \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Freeze parameters (weights) in model’s lower convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Add custom classifier with several layers of trainable parameters to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output) #converts the multi-dimensional  output to 1D\n",
    "x = Dense(256, activation='relu')(x)  #RELU to introduce non-linearity mitigate the vanishing gradient problem \n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)  \n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Train classifier layers on training data available for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 208ms/step - accuracy: 0.2084 - loss: 2.1658 - val_accuracy: 0.4360 - val_loss: 1.5878\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 230ms/step - accuracy: 0.4068 - loss: 1.6620 - val_accuracy: 0.5000 - val_loss: 1.4321\n",
      "Epoch 3/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 241ms/step - accuracy: 0.4851 - loss: 1.4704 - val_accuracy: 0.5200 - val_loss: 1.3678\n",
      "Epoch 4/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 204ms/step - accuracy: 0.4954 - loss: 1.4156 - val_accuracy: 0.5090 - val_loss: 1.3584\n",
      "Epoch 5/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 207ms/step - accuracy: 0.5541 - loss: 1.2826 - val_accuracy: 0.5430 - val_loss: 1.3192\n",
      "Epoch 6/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 199ms/step - accuracy: 0.5662 - loss: 1.2295 - val_accuracy: 0.5440 - val_loss: 1.3006\n",
      "Epoch 7/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 199ms/step - accuracy: 0.5936 - loss: 1.1786 - val_accuracy: 0.5390 - val_loss: 1.3083\n",
      "Epoch 8/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 201ms/step - accuracy: 0.5947 - loss: 1.1343 - val_accuracy: 0.5420 - val_loss: 1.3003\n",
      "Epoch 9/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 201ms/step - accuracy: 0.6099 - loss: 1.1028 - val_accuracy: 0.5410 - val_loss: 1.3216\n",
      "Epoch 10/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 200ms/step - accuracy: 0.6225 - loss: 1.0715 - val_accuracy: 0.5550 - val_loss: 1.3152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27a6adbd250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m 2/79\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 1s/step - accuracy: 0.0820 - loss: 2.4009"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3))\n",
    "# freeze all layers first\n",
    "for layer in base_model.layers:\n",
    "   layer.trainable = False\n",
    "# unfreeze last 4 layers of base model\n",
    "for layer in base_model.layers[len(base_model.layers) - 4:]:\n",
    "   layer.trainable = True\n",
    "# fine-tuning hyper parameters\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# training fine tuned model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predicted_value = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 890   #index of test image \n",
    "plt.imshow(x_test[n])\n",
    "print(\"Preditcted: \",labels[np.argmax(predicted_value[n])])\n",
    "print(\"Actual: \", labels[np.argmax(y_test[n])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
